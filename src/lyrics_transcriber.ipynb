{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5adccf03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.3 (tags/v3.13.3:6280bb5, Apr  8 2025, 14:47:33) [MSC v.1943 64 bit (AMD64)]\n",
      "numpy      2.2.6\n",
      "pandas     2.2.3\n",
      "pandas     2.2.3\n",
      "torch      2.8.0+cpu\n",
      "torchaudio 2.8.0+cpu\n",
      "whisperx   (no __version__)\n",
      "demucs     4.0.1\n",
      "\n",
      "Note: For WhisperX, use the Python 3.13 env we created: .venv-whisperx-py313.\n",
      "In VS Code, change the Notebook kernel (top-right) to that interpreter for this notebook.\n",
      "torch      2.8.0+cpu\n",
      "torchaudio 2.8.0+cpu\n",
      "whisperx   (no __version__)\n",
      "demucs     4.0.1\n",
      "\n",
      "Note: For WhisperX, use the Python 3.13 env we created: .venv-whisperx-py313.\n",
      "In VS Code, change the Notebook kernel (top-right) to that interpreter for this notebook.\n"
     ]
    }
   ],
   "source": [
    "# Environment check: run this first in the WhisperX env\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "def _ver(mod):\n",
    "    try:\n",
    "        m = importlib.import_module(mod)\n",
    "        return getattr(m, \"__version__\", \"(no __version__)\"), None\n",
    "    except Exception as e:\n",
    "        return None, f\"{type(e).__name__}: {e}\"\n",
    "\n",
    "mods = [\n",
    "    (\"numpy\",), (\"pandas\",), (\"torch\",), (\"torchaudio\",), (\"whisperx\",), (\"demucs\",)\n",
    "]\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "for (name,) in mods:\n",
    "    v, err = _ver(name)\n",
    "    if v:\n",
    "        print(f\"{name:10s}\", v)\n",
    "    else:\n",
    "        print(f\"{name:10s}\", \"ERROR:\", err)\n",
    "\n",
    "print(\"\\nNote: For WhisperX, use the Python 3.13 env we created: .venv-whisperx-py313.\\n\"\n",
    "      \"In VS Code, change the Notebook kernel (top-right) to that interpreter for this notebook.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecbf948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating vocals from music with Demucs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:213: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.load_with_torchcodec` under the hood. Some parameters like ``normalize``, ``format``, ``buffer_size``, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's decoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.decoders.AudioDecoder.html#torchcodec.decoders.AudioDecoder.\n",
      "  warnings.warn(\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
      "  warnings.warn(\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\torchaudio\\_backend\\utils.py:337: UserWarning: In 2.9, this function's implementation will be changed to use torchaudio.save_with_torchcodec` under the hood. Some parameters like format, encoding, bits_per_sample, buffer_size, and ``backend`` will be ignored. We recommend that you port your code to rely directly on TorchCodec's encoder instead: https://docs.pytorch.org/torchcodec/stable/generated/torchcodec.encoders.AudioEncoder\n",
      "  warnings.warn(\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\ctranslate2\\__init__.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocals extracted to: C:\\Users\\marcu\\AppData\\Local\\Temp\\tmptd2te9ur.wav\n",
      "Loading WhisperX model (base.en)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 18:06:14 - whisperx.vads.pyannote - INFO - Performing voice activity detection using Pyannote...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python313\\Lib\\inspect.py:1020: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.6. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\whisperx\\assets\\pytorch_model.bin`\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "e:\\Documents\\CodeStuff\\BLAiRE\\.venv-whisperx-py313\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.4.0. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.8.0+cpu. Bad things might happen unless you revert torch to 1.x.\n",
      "Transcribing audio...\n",
      "Transcribing audio...\n",
      "Loading alignment model...\n",
      "Loading alignment model...\n",
      "Aligning words...\n",
      "Aligning words...\n",
      "Aligned 17 words from YOUR lyrics\n",
      "\n",
      "Your lyrics with timings:\n",
      "0: 'i' - 2.71s to 3.56s\n",
      "1: 'spend' - 3.58s to 3.88s\n",
      "2: 'my' - 4.74s to 4.78s\n",
      "3: 'life' - 4.80s to 5.04s\n",
      "4: 'doing' - 5.45s to 6.01s\n",
      "5: 'anything' - 6.17s to 6.83s\n",
      "6: 'you' - 6.89s to 7.09s\n",
      "7: 'like' - 7.13s to 7.50s\n",
      "8: 'come' - 7.86s to 8.12s\n",
      "9: 'on' - 8.60s to 8.98s\n",
      "10: 'and' - 9.16s to 9.32s\n",
      "11: 'love' - 9.49s to 9.63s\n",
      "12: 'me' - 9.93s to 10.27s\n",
      "13: 'like' - 10.69s to 11.17s\n",
      "14: 'you' - 11.19s to 11.26s\n",
      "15: 'used' - 11.39s to 11.86s\n",
      "16: 'to' - 11.96s to 12.00s\n",
      "Aligned 17 words from YOUR lyrics\n",
      "\n",
      "Your lyrics with timings:\n",
      "0: 'i' - 2.71s to 3.56s\n",
      "1: 'spend' - 3.58s to 3.88s\n",
      "2: 'my' - 4.74s to 4.78s\n",
      "3: 'life' - 4.80s to 5.04s\n",
      "4: 'doing' - 5.45s to 6.01s\n",
      "5: 'anything' - 6.17s to 6.83s\n",
      "6: 'you' - 6.89s to 7.09s\n",
      "7: 'like' - 7.13s to 7.50s\n",
      "8: 'come' - 7.86s to 8.12s\n",
      "9: 'on' - 8.60s to 8.98s\n",
      "10: 'and' - 9.16s to 9.32s\n",
      "11: 'love' - 9.49s to 9.63s\n",
      "12: 'me' - 9.93s to 10.27s\n",
      "13: 'like' - 10.69s to 11.17s\n",
      "14: 'you' - 11.19s to 11.26s\n",
      "15: 'used' - 11.39s to 11.86s\n",
      "16: 'to' - 11.96s to 12.00s\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import whisperx\n",
    "import re\n",
    "\n",
    "# Install: pip install demucs\n",
    "import torch\n",
    "import torchaudio\n",
    "from demucs.pretrained import get_model\n",
    "from demucs.apply import apply_model\n",
    "\n",
    "song_path = 'shoobie.wav'\n",
    "lyrics_text = \"\"\"\n",
    "I spend my life\n",
    "doing anything you like\n",
    "come on, and love me like you used to\n",
    "\"\"\"\n",
    "\n",
    "# Options\n",
    "use_vocal_separation = True\n",
    "whisperx_model_size = \"base.en\"\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "def extract_vocals(audio_path):\n",
    "    \"\"\"Separate vocals using Demucs (no DLL issues on Windows)\"\"\"\n",
    "    print(\"Separating vocals from music with Demucs...\")\n",
    "    \n",
    "    # Load model\n",
    "    model = get_model('htdemucs')\n",
    "    model.cpu()\n",
    "    model.eval()\n",
    "    \n",
    "    # Load audio\n",
    "    wav, sr = torchaudio.load(audio_path)\n",
    "    \n",
    "    # Apply separation\n",
    "    with torch.no_grad():\n",
    "        sources = apply_model(model, wav[None], device='cpu')[0]\n",
    "    \n",
    "    # Extract vocals (index 3)\n",
    "    vocals = sources[3]\n",
    "    \n",
    "    # Save to temp file - FIXED: Use NamedTemporaryFile instead of mktemp\n",
    "    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:\n",
    "        temp_vocals = tmp.name\n",
    "    \n",
    "    torchaudio.save(temp_vocals, vocals, sr)\n",
    "    \n",
    "    print(f\"Vocals extracted to: {temp_vocals}\")\n",
    "    return temp_vocals\n",
    "\n",
    "\n",
    "def align_lyrics_to_audio(audio_path, lyrics_text, use_vocal_separation=True):\n",
    "    \"\"\"\n",
    "    Takes YOUR lyrics and aligns them to the audio using WhisperX\n",
    "    \n",
    "    Args:\n",
    "        audio_path: Path to audio file\n",
    "        lyrics_text: YOUR lyrics as a string\n",
    "        use_vocal_separation: Whether to use Spleeter first\n",
    "    \n",
    "    Returns:\n",
    "        List of word timings matching YOUR lyrics\n",
    "    \"\"\"\n",
    "    # Step 1: Extract vocals if enabled\n",
    "    if use_vocal_separation:\n",
    "        audio_to_use = extract_vocals(audio_path)\n",
    "    else:\n",
    "        audio_to_use = audio_path\n",
    "    \n",
    "    # Step 2: Load WhisperX model\n",
    "    print(f\"Loading WhisperX model ({whisperx_model_size})...\")\n",
    "    model = whisperx.load_model(whisperx_model_size, device, compute_type=\"float32\")\n",
    "    \n",
    "    # Step 3: Load audio\n",
    "    audio = whisperx.load_audio(audio_to_use)\n",
    "    \n",
    "    # Step 4: Transcribe to get initial segments\n",
    "    print(\"Transcribing audio...\")\n",
    "    result = model.transcribe(audio, batch_size=16, language=\"en\")\n",
    "    \n",
    "    # Step 5: Load alignment model for word-level timestamps\n",
    "    print(\"Loading alignment model...\")\n",
    "    model_a, metadata = whisperx.load_align_model(language_code=\"en\", device=device)\n",
    "    \n",
    "    # Step 6: Align to get precise word timings\n",
    "    print(\"Aligning words...\")\n",
    "    result_aligned = whisperx.align(\n",
    "        result[\"segments\"], \n",
    "        model_a, \n",
    "        metadata, \n",
    "        audio, \n",
    "        device,\n",
    "        return_char_alignments=False\n",
    "    )\n",
    "    \n",
    "    # Step 7: Extract word timings from WhisperX\n",
    "    whisperx_words = []\n",
    "    for segment in result_aligned[\"segments\"]:\n",
    "        for word_info in segment.get(\"words\", []):\n",
    "            whisperx_words.append({\n",
    "                'word': word_info['word'].strip().lower(),\n",
    "                'start': word_info['start'],\n",
    "                'end': word_info['end']\n",
    "            })\n",
    "    \n",
    "    # Step 8: Parse YOUR lyrics into words\n",
    "    # TODO: Use LLM to parse lyrics into usable format\n",
    "    your_words = re.findall(r'\\b\\w+\\b', lyrics_text.lower())\n",
    "    \n",
    "    # Step 9: Match your lyrics words to WhisperX's timed words\n",
    "    word_timings = []\n",
    "    whisperx_idx = 0\n",
    "    \n",
    "    for your_word in your_words:\n",
    "        # Find matching word in WhisperX results\n",
    "        while whisperx_idx < len(whisperx_words):\n",
    "            whisperx_word = whisperx_words[whisperx_idx]['word']\n",
    "            \n",
    "            if your_word in whisperx_word or whisperx_word in your_word:\n",
    "                # Found a match\n",
    "                word_timings.append({\n",
    "                    'word': your_word,\n",
    "                    'start': whisperx_words[whisperx_idx]['start'],\n",
    "                    'end': whisperx_words[whisperx_idx]['end']\n",
    "                })\n",
    "                whisperx_idx += 1\n",
    "                break\n",
    "            else:\n",
    "                whisperx_idx += 1\n",
    "        else:\n",
    "            # No match found, estimate timing\n",
    "            if word_timings:\n",
    "                # Use previous word's end time\n",
    "                last_end = word_timings[-1]['end']\n",
    "                word_timings.append({\n",
    "                    'word': your_word,\n",
    "                    'start': last_end,\n",
    "                    'end': last_end + 0.5  # Estimate 0.5s duration\n",
    "                })\n",
    "    \n",
    "    print(f\"Aligned {len(word_timings)} words from YOUR lyrics\")\n",
    "    return word_timings\n",
    "\n",
    "\n",
    "# Run the alignment\n",
    "word_timings = align_lyrics_to_audio(song_path, lyrics_text, use_vocal_separation)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nYour lyrics with timings:\")\n",
    "for i, word_data in enumerate(word_timings):\n",
    "    print(f\"{i}: '{word_data['word']}' - {word_data['start']:.2f}s to {word_data['end']:.2f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-whisperx-py313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
